---
article_type: article
author: "Maarja Olesk"
lang: en
news_title: "TalTech Researcher: There Are Grey Areas in Using Language Data in Speech Recognition"
preview: "Tanel Alumäe, senior researcher and head of the language technology lab at Taltech explains the open data portal how scientists reuse data to develop speech recognition models, what issues have emerged in data usage and why collecting digital speech data is a matter of life and death for the Estonian language."
preview_img: language-tech1.jpg
submitted: 2020/08/31
tags:
  - open data
  - language technology
  - speech recognition
  - machine learning
text: |
  <p><b>Tanel Alumäe, senior researcher and head of the language technology lab at Taltech explains the open data portal how scientists reuse data to develop speech recognition models, what issues have emerged in data usage and why collecting digital speech data is a matter of life and death for the Estonian language.</b></p>
  <p><b>Your research team develops speech recognition technologies. How would you explain what this technology can do to someone who doesn’t know much about this field?</b></p>
  <p>Speech recognition turns human speech into written text. This could be a longer recording such as our interview or a shorter sentence, but essentially speech goes in and text comes out. In the case of longer transcripts, we would also like the text to contain punctuation marks and specify who is talking at a given moment – for example, a transcript of a dialogue could have names attached to sentences. Speech recognition is also used when giving voice commands to smartphones. For example, Android has an app called Kõnele, which enables using speech recognition to complete any text box in any Android application.</p>
  <p><b>Who are the main users of these services? </b></p>
  <p><a href="http://bark.phon.ioc.ee/webtrans/">Our online automatic transcription application</a> is used, for instance, by journalists who need to transcribe longer interviews, also researchers in humanities and social sciences whose job often involves conducting interviews. The transcription of meetings is a promising area because meeting minutes often need to be produced afterwards, which is a tedious and time-consuming task. Speech recognition helps create meeting minutes faster and better.</p>
  <p><b>How well do these technologies work?</b></p>
  <p>We are continuously monitoring the percentage of mistakes. This depends a lot on the material that goes into the system. We see the least errors in transcripts of radio news and talk shows – they have professional speakers, good technology and people usually take turns to speak, so errors remain below 10 percent. Speech recognition has a harder time coping with speech that is spontaneous, grammatically incorrect and when the pronunciation is lazy – think about the way we talk to a friend in a bar. Or if the quality of the sound is poor, for example when you place a phone in the middle a table to record a meeting with ten participants so that everyone is quite far from the device and a lot of noise gets in. This is difficult for a human being to understand, likewise for a computer program.</p>
  <p><b>What kind of data do you use as input when training speech recognition models?</b></p>
  <p>Speech recognition models are based on machine learning and for machine learning we need training data. Speech recognition uses two types of input data: speech data and textual data. Speech data or speech corpora are datasets that contain human speech and the corresponding written text. For training we use audio recordings and human-made error-free transcripts of the recordings, for example recordings of radio shows or phone calls. It would be good if the training data would be similar to the kind of data that will be fed into the application later. For Estonian-language speech recognition we use about 400 hours of manually transcribed speech as training data – this includes radio talk shows, news, recordings of lectures and conference presentations. We use a lot of telephone interviews from radio broadcasts because this gives us a variety of different voices. We generate the datasets based on data that are already available online, or we use our research funds to have lectures manually transcribed.</p>
  <p><b>What kind of support do you get from the existing language data infrastructure in Estonia such as the repository of the Center of Estonian Language Resources?</b></p>
  <p>We usually generate the data resources that we need on our own but once the resources are there, the center helps manage and disseminate them. For example, we’re providing our speech data through the repository but we use the repository to get textual data – that is pure text without speech. These are necessary to train the language models used in speech recognition that statistically describe how frequently certain words or word combinations occur in Estonian. Everything the model knows is based on it having seen huge volumes of the Estonian language; due to this we need loads of data to train the model. These usually come from online resources – texts published on the web, newspaper articles, Wikipedia, books… Transcripts of speech are also important because written language differs from spoken language. Such texts are available in the language corpora of the center. We once used to collect text data on our own but ever since large national language corpora became available in the Estonian language, they have been more convenient to use.</p>
  <p><b>What part of these data has been published as open data? How has the availability of open data affected your work?</b></p>
  <p>As far as I understand, the data that we use today are not open data – some datasets do have a Creative Commons license attached to them but also a note stating “usage restricted“. As our main data source, we use ENC (<i>Estonian National Corpus</i>), which is hosted by the Center of Estonian Language Resources. But there is a lot of grey area around language data – the data mostly come from online resources, all of the sources have their own licenses and authors, but nobody has asked for their permission to add these data to the national corpus. The center employs a legal expert who sometimes writes articles about this topic but as far as I know there is no good solution yet.</p>
  <p>For the time being, scientists can use these data for research, but if I take the training data to build a model then it is not clear if I can use this for scientific purposes only or also for commercial purposes. We haven’t commercialized our technology so far, but we do offer it for free to everyone, including those who may wish to use it for commercial purposes.</p>
  <p><b>How mature are similar technologies in other countries compared to Estonia?</b></p>
  <p>Estonia is in an exceptional position here. In larger countries it is not research institutions but private companies who develop speech recognition technologies for broad use and who also commercialize these technologies. In the case of the Estonian language this is believed not to pay off. Due to this, the development of language technologies has been funded by the government so far. Considering that the number of Estonian-speakers in the world is about a million, I doubt there is another language with such a small number of users where speech recognition technology would be as developed as it is here. However, in larger countries the level is higher because more people work on developing the technology and they have access to much bigger volumes of training data.</p>
  <p>In Estonia, the government has funded the development of the technology and we have used the funding to create speech corpora. It is very important for the collection of speech data to continue. For example, we will soon publish a new corpus with almost 400 hours of material from the Estonian National Broadcasting’s TV and radio archives. Once these data exist, the development of the technology itself is not very complicated, but I doubt this will pay off commercially.</p>
  <p><b>Where do you think the world of speech recognition is heading to, both in Estonia and in the world? What could be possible in 5 or 10 years thanks to Estonian-language speech recognition technologies?</b></p>
  <p>One of the areas where speech recognition could do more is meeting transcripts. For me, the Holy Grail of speech recognition would be an application that would automatically produce clean meeting minutes immediately after a meeting has ended. A certain degree of intelligence is needed for that, but this task can also be automated to a large extent if the data are there. Such a solution would be useful in a lot of domains, from government institutions to private companies.</p>
  <p>We are hoping to launch a project soon which will use speech recognition to automatically produce Estonian subtitles for Estonian TV shows, including live broadcasts. This would be extremely useful for people with hearing impairments or even just to someone who wants to quietly watch TV at home in the evening while their children sleep. This involves many technological complexities – we cannot guarantee that the system never gets it wrong, for example if there is a lot of background noise. But the system could at least learn to recognize situations where it is very likely to make a mistake, and not produce subtitles in such circumstances.</p>
  <p>But one of the most fascinating things in speech technology is combining speech recognition with translation. Microsoft and Google are already working on it and are making a lot of progress. Simply put, I speak Spanish, you speak Chinese and we can talk to each other – I hear automatic translation from my headphones and it preserves your voice and intonation, like in sci-fi books. This could be progress for the whole humankind!</p>
  <p><b>Such solutions are mostly developed by large multinational corporations – how does Estonian language get into their applications? Are Estonian scientists collaborating with Google and Microsoft?</b></p>
  <p>This is a big concern. Google once said at a conference that their aim is to create speech recognition technology for all languages with more than a million users. They showed a map and Estonia was just a nice blank spot there. These systems have a very closed nature, third parties do not have much leverage to integrate their technologies or ask large corporations to develop their technologies in Estonian. The only thing we can do is provide training data.</p>
  <p>In the US, virtual assistants such as Amazon’s Alexa or Google Home are also very popular – they’re like small jars on the shelf that you can talk to. People often ask us when we will have that in Estonian, but we have to tell them not in the next ten years. There’s nothing we can do about it. The development of virtual assistants requires a lot of language-specific manual work. To do that, Google would have to employ 100 Estonian-speaking assistants for several years. Another alternative is waiting for some sort of a technological breakthrough to happen. I think this is a more likely scenario than getting tech giants interested in Estonian.</p>
  <p>Nevertheless, it is extremely important for the government to continue supporting the development of Estonian language technologies. If we have no language technology of our own, we will soon find ourselves speaking English both with our computers and with each other.</p>
  ______
  <p><em>This interview is part of our blog’s two-part series on the role of data in language technology.</p>
  <p>The Open Data Portal's content is created as part of the EU structural funds' programme 'Raising Public Awareness about the Information Society' financed through the EU Regional Development Fund. The project is implemented by Open Knowledge Estonia.</em></p>

---